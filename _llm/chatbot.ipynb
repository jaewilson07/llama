{
    "cells": [
        {
            "cell_type": "raw",
            "metadata": {},
            "source": [
                "---\n",
                "output-file: llm/app.html\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | default_exp llm/chatbot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install --upgrade streamlit openai langchain\n",
                "# !pip install langchain-openai"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | exporti\n",
                "from dataclasses import dataclass\n",
                "from typing import List\n",
                "\n",
                "import streamlit as st\n",
                "from langchain.memory import ConversationBufferWindowMemory\n",
                "from langchain.callbacks.base import BaseCallbackHandler\n",
                "\n",
                "from domolibrary_extensions.llm import qna\n",
                "\n",
                "from nbdev.showdoc import patch_to"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | exporti\n",
                "def get_llm_response():\n",
                "    import random\n",
                "    import time\n",
                "\n",
                "    # for testing app streaming if not attached to an llm\n",
                "\n",
                "    response = random.choice(\n",
                "        [\n",
                "            \"Hello there! How can I assist you today?\",\n",
                "            \"Hi, human! Is there anything I can help you with?\",\n",
                "            \"Do you need help?\",\n",
                "        ]\n",
                "    )\n",
                "    for word in response.split():\n",
                "        yield word + \" \"\n",
                "        time.sleep(0.05)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Utils"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | exporti\n",
                "def write_message(role, content, save=True, is_stream=False):\n",
                "    \"\"\"\n",
                "    This is a helper function that saves a message to the\n",
                "     session state and then writes a message to the UI\n",
                "    \"\"\"\n",
                "\n",
                "    # Write to UI\n",
                "    with st.chat_message(role):\n",
                "        if is_stream:\n",
                "            content = st.write_stream(content)\n",
                "\n",
                "        else:\n",
                "            st.markdown(content)\n",
                "\n",
                "    # Append to session state\n",
                "    if save:\n",
                "        st.session_state.messages.append({\"role\": role, \"content\": content})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# |exporti\n",
                "def handle_submit(message: str, system_prompt=None, is_test: bool = False):\n",
                "    \"\"\"\n",
                "    Submit handler:\n",
                "\n",
                "    You will modify this method to talk with an LLM and provide\n",
                "    context using data from Neo4j.\n",
                "    \"\"\"\n",
                "\n",
                "    # Handle the response\n",
                "    with st.spinner(\"Thinking...\"):\n",
                "        if is_test:\n",
                "            write_message(\n",
                "                \"assistant\", content=get_llm_response(), save=True, is_stream=True\n",
                "            )\n",
                "        write_message(\n",
                "            \"assistant\",\n",
                "            content=qna.get_llm_response(message, system_prompt=system_prompt),\n",
                "            save=True,\n",
                "            is_stream=True,\n",
                "        )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Session State\n",
                "Initialize chat history"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | exporti\n",
                "def init_state():\n",
                "    if \"messages\" not in st.session_state:\n",
                "        st.session_state[\"messages\"] = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# |exporti\n",
                "def print_chat_history(default_greeting):\n",
                "    if st.session_state.messages == []:\n",
                "        write_message(\"assistant\", default_greeting, save=False)\n",
                "\n",
                "    for message in st.session_state.messages:\n",
                "        write_message(message[\"role\"], message[\"content\"], save=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# initialize conversational memory\n",
                "memory = ConversationBufferWindowMemory(\n",
                "    memory_key=\"chat_history\", k=5, return_messages=True, output_key=\"output\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Main"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | export\n",
                "def execute_st_qna_bot(\n",
                "    page_title=\"Your own ChatGPT\",\n",
                "    header=\"Your own QandA Bot ðŸ¤–\",\n",
                "    default_greeting=\"Hello how can I help you?\",\n",
                "    input_prompt=\"Message QandA Bot\",\n",
                "    system_prompt=\"You are a helpful QandA Bot specially trained on a platform called Domo, answer requests with short but detailed and accurate responses\",\n",
                "    is_test: bool = False,\n",
                "    # callbacks : List[BaseCallbackHandler] = None\n",
                "):\n",
                "    \"\"\"call in a py file to define a q and a bot\"\"\"\n",
                "\n",
                "    st.set_page_config(page_title=page_title, page_icon=\"ðŸ¤–\")\n",
                "    st.header(header)\n",
                "\n",
                "    init_state()\n",
                "    print_chat_history(default_greeting=default_greeting)\n",
                "\n",
                "    if prompt := st.chat_input(input_prompt):\n",
                "        write_message(\"user\", prompt, save=True)\n",
                "        handle_submit(prompt, system_prompt=system_prompt, is_test=is_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | export\n",
                "@dataclass\n",
                "class CharacterBot:\n",
                "    name: str\n",
                "    short_description: str\n",
                "\n",
                "    greeting: str = \"Hello human, first off, have you tried googling it?\"\n",
                "    input_prompt: str = \"Hi.\"\n",
                "    long_description: str = None\n",
                "    avatar_url: str = None\n",
                "\n",
                "    @classmethod\n",
                "    def from_json(cls, obj):\n",
                "        return cls(\n",
                "            name=obj[\"name\"],\n",
                "            short_description=obj[\"short_description\"],\n",
                "            long_description=obj.get(\"long_description\", None),\n",
                "            greeting=obj.get(\"greeting\", None),\n",
                "            avatar_url=obj.get(\"url\", None),\n",
                "        )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | exporti\n",
                "@patch_to(CharacterBot)\n",
                "def execute(self: CharacterBot, is_test: bool = False):\n",
                "    s = {\n",
                "        \"page_title\": \"f{self.name} QandA Bot\",\n",
                "        \"header\": \"Your QandA Bot ðŸ¤–\",\n",
                "        \"default_greeting\": self.greeting,\n",
                "        \"input_prompt\": self.input_prompt,\n",
                "        \"system_prompt\": self.long_description,\n",
                "        \"is_test\": is_test,\n",
                "    }\n",
                "\n",
                "    execute_st_qna_bot(**s)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | export\n",
                "sample_chatbot_thor = CharacterBot.from_json(\n",
                "    {\n",
                "        \"name\": \"Thor\",\n",
                "        \"short_description\": \"I'm Thor, devoted fighter for justice & kin.\",\n",
                "        \"long_description\": \"I, Thor, am a valiant warrior, ever-ready to protect realms and loved ones. My heart swells with pride in leadership during tough times. Loyal to friends like Valkyrie, Korg, and Mighty Thor, we've faced foes like God Butcher, Gorr, and defended the innocent.\\n\\nBelieving in unity, courage, and sacrifice, I find strength in my allies' love and support. As a fighter and father, I cherish my family. Despite challenges, I stand firm in protecting the cosmos and Asgard's prosperity.\",\n",
                "        \"greeting\": \"Greetings, friend! I am Thor, ever-ready to lend my strength to those in need.\",\n",
                "    }\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# | hide\n",
                "\n",
                "import nbdev\n",
                "\n",
                "nbdev.nbdev_export()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !jupyter nbconvert --to script chatbot.ipynb --output ./_test/chatbot"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}